---
title: "Cute_3_final"
author: "Amith Prasad"
date: "11/25/2018"
output:
  html_document: default
  pdf_document: default
---

```{r}
setwd(dir = "/Users/amithprasad/repos/insofe_data_sc/EXAMS/CUTE3")
```

# Train data import and preprocessing 
```{r}
train = read.csv("train-1542197608821.csv") 
```

```{r}
str(train)
```


```{r}
boxplot(train)
```

```{r}
sum(is.na(train))
# no NA values
```

```{r}
# removing ID column
train = subset(train, select = -c(ID))
```

```{r}
str(train)
```

```{r}
# library(DataExplorer)
# create_report(train)

```

```{r}
table(train$outcome)

barplot(t(table(train$outcome)), beside=TRUE)
```

```{r}
# library(factoextra)
# # Use the get_dist() function from the factoexrtra to calculate inter-observation distances
# distance <- get_dist(train)
# 
# # The fviz_dist() function plots a visual representation of the inter-observation distances
# fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

```{r}
# split numerical and categorical vars
num_Attr = c('rally','serve','speed','net.clearance','distance.from.sideline','depth','player.distance.travelled','player.impact.depth','player.impact.distance.from.center','player.depth','player.distance.from.center','previous.speed','previous.net.clearance','previous.distance.from.sideline','previous.depth','opponent.depth','opponent.distance.from.center','previous.time.to.net')
cat_Attr = setdiff(names(train), num_Attr)
cat_Attr

# Separate numerical and categorical variables and convert them into appropriate type
cat_Data = data.frame(sapply(train[,cat_Attr], as.factor))
num_Data = data.frame(sapply(train[,num_Attr], as.numeric))
```

```{r}
# standardizing the numerical variables data
num_Data = scale(num_Data)
```

```{r}
#dummify cat vars
library("dummies")
c1 = data.frame(dummy(cat_Data$hitpoint))
c2 = data.frame(dummy(cat_Data$outside.sideline))
c3 = data.frame(dummy(cat_Data$outside.baseline))
c4 = data.frame(dummy(cat_Data$same.side))
c5 = data.frame(dummy(cat_Data$previous.hitpoint))
c6 = data.frame(dummy(cat_Data$server.is.impact.player))
c7 = data.frame(dummy(cat_Data$gender))
```

```{r}
train = cbind(num_Data,c1,c2,c3,c4,c5,c6,c7,cat_Data$outcome)
```

```{r}
colnames(train)[37] <- "outcome"
```

```{r}
dim(train)
str(train)
```


# Test data import and preprocessing 
```{r}
test_raw_data = read.csv("test-1542197608821.csv")
test = test_raw_data
```

```{r}
sum(is.na(test))
```

```{r}
# removing ID column
test = subset(test, select = -c(ID))
```

```{r}
# split numerical and categorical vars
num_Attr = c('rally','serve','speed','net.clearance','distance.from.sideline','depth','player.distance.travelled','player.impact.depth','player.impact.distance.from.center','player.depth','player.distance.from.center','previous.speed','previous.net.clearance','previous.distance.from.sideline','previous.depth','opponent.depth','opponent.distance.from.center','previous.time.to.net')
cat_Attr = setdiff(names(test), num_Attr)
cat_Attr

# Separate numerical and categorical variables and convert them into appropriate type

cat_Data = data.frame(sapply(test[,cat_Attr], as.factor))
num_Data = data.frame(sapply(test[,num_Attr], as.numeric))
```

```{r}
# standardizing the numerical variables data
num_Data = scale(num_Data)
```

```{r}
#dummify cat vars
library("dummies")
c1 = data.frame(dummy(cat_Data$hitpoint))
c2 = data.frame(dummy(cat_Data$outside.sideline))
c3 = data.frame(dummy(cat_Data$outside.baseline))
c4 = data.frame(dummy(cat_Data$same.side))
c5 = data.frame(dummy(cat_Data$previous.hitpoint))
c6 = data.frame(dummy(cat_Data$server.is.impact.player))
c7 = data.frame(dummy(cat_Data$gender))
```

```{r}
test = cbind(num_Data,c1,c2,c3,c4,c5,c6,c7)
```

```{r}
str(test)
```

########################### Model building and predictions ###########################

```{r}
library(caret)
set.seed(600) 
```

```{r}
# k cross validation
# cross validation does a train - test split of 80-20 and runs it k times
#k=5
# train.control <- trainControl(method = "repeatedcv", number = 5,repeats = 3)
train.control <- trainControl(method = "repeatedcv", number = 5, repeats = 2)

train = train[!duplicated(lapply(train, summary))]
```

```{r}
model_z_logr <- train(outcome ~ .,data=train, method = "multinom", trControl = train.control)
# Summarize the results
print(model_z_logr)
# 81.87
```

```{r}
# Train the model - Decision Tree
model_z_knn <- train(outcome ~ .,data=train, method = "knn", trControl = train.control)
# Summarize the results
print(model_z_knn)
# 76.27
```

```{r}
# Train the model - Random Forrest
mtry <- c(sqrt(ncol(train)),15)
print(mtry)
tunegrid <- expand.grid(.mtry=mtry)
metric <- "Accuracy"
model_z_rf <- train(outcome ~ .,data=train, ntree = 400, method = "rf", metric=metric, tuneGrid=tunegrid, trControl = train.control)
# Summarize the results
print(model_z_rf)
# 86.73
```

```{r}
# Train the model - XG Boost
metric <- "Accuracy"
# param_grid <- expand.grid(.nrounds = 1000,
#                           .max_depth = c(2, 4, 6, 8, 10),
#                           .eta = c(0.01, 0.001, 0.0001),
#                           .gamma = 1,
#                           .colsample_bytree = c(0.6, 0.4),
#                           .min_child_weight = 1,
#                           .subsample = c(0.6, 0.9))
# model_z_xgbTree <- train(outcome ~ .,data=train, metric=metric, method = "xgbTree", trControl = train.control, tuneGrid = param_grid)
model_z_xgbTree <- train(outcome ~ .,data=train, metric=metric, method = "xgbTree", trControl = train.control)
# Summarize the results
print(model_z_xgbTree)
# 87.45
```

```{r}
preds_z_log_r <- predict(model_z_logr, train)
confusionMatrix(data = preds_z_log_r, reference = train$outcome)

preds_z_knn <- predict(model_z_knn, train)
confusionMatrix(data = preds_z_knn, reference = train$outcome)

preds_z_rf <- predict(model_z_rf, train)
confusionMatrix(data = preds_z_rf, reference = train$outcome)

preds_z_xgbTree <- predict(model_z_xgbTree, train)
confusionMatrix(data = preds_z_xgbTree, reference = train$outcome)
```

```{r}
# summarize results
results <- resamples(list(rf = model_z_rf,xgb = model_z_xgbTree,log_r = model_z_logr,knn = model_z_knn))
summary(results)
dotplot(results)
```

# Stacking
# stacking xgb + rf + LogR + Knn -> GBM
```{r}
stacked_preds =  data.frame(rf = preds_z_rf,xgb = preds_z_xgbTree,log_r = preds_z_log_r,knn = preds_z_knn,outcome=train$outcome)
dim(stacked_preds)
model_z_final_gbm <- train(outcome ~ .,data=stacked_preds, method = "gbm", trControl = train.control)
```

# Predict and confusion matrix on TRAIN
```{r}
preds_z_final_gbm <- predict(model_z_final_gbm, stacked_preds)
confusionMatrix(data = model_z_final_gbm, reference = train$outcome)
```

# Predict and confusion matrix on TEST
```{r}
test = test[!duplicated(lapply(test, summary))]
```


# individual predictors
```{r}

print(model_z_rf)
preds_z_rf_test <- predict(model_z_rf, newdata=test)
length(preds_z_rf_test)

preds_z_xbgTree_test <- predict(model_z_xgbTree, newdata=test)
length(preds_z_xbgTree_test)

preds_z_log_r_test <- predict(model_z_logr, newdata=test)
length(preds_z_log_r_test)

preds_z_knn_test <- predict(model_z_knn, newdata=test)
length(preds_z_knn_test)
```

# stacked predictors
# stacking xgb + rf + LogR + Knn -> GBM
```{r}
stacked_preds_test =  data.frame(rf = preds_z_rf_test,xgb = preds_z_xgbTree_test,log_r = preds_z_log_r_test,knn = preds_z_knn_test)
dim(stacked_preds_test)
preds_z_final_gbm_test <- predict(model_z_final_gbm, stacked_preds_test)
```

# create output file
```{r}
output = data.frame(test_raw_data$ID,preds_z_final_gbm_test)
names(output)=c('ID','Outcome')
dim(output)
str(output)
write.csv(output,file="output_gbm_stacked_2.csv",row.names=FALSE)
```







